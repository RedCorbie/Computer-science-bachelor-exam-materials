\documentclass[a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[english, russian]{babel}
\usepackage[fleqn]{amsmath}
\usepackage{amsfonts, amssymb, amsthm, mathtools}

\usepackage{mathtools}
\usepackage{fullpage}
\usepackage[colorinlistoftodos]{todonotes}


\title{Алгоритмы и структуры данных}
\author{MIPT DIHT}
\begin{document}
\maketitle

\section{Сортировки}
\subsection{Quick Sort}
\subsubsection{Шаги}
\begin{itemize}
	\item  Выбираем в массиве некоторый элемент, который будем называть опорным элементом. Известные стратегии: выбирать постоянно один и тот же элемент, например, средний или последний по положению; выбирать элемент со случайно выбранным индексом. Часто хороший результат даёт выбор в качестве опорного элемента среднего арифметического между минимальным и максимальным элементами массива.
	\item Операция разделения массива: реорганизуем массив таким образом, чтобы все элементы со значением меньшим или равным опорному элементу, оказались слева от него, а все элементы, превышающие по значению опорный — справа от него. Обычный алгоритм операции:
	\begin{enumerate}
		\item Два индекса — l и r, приравниваются к минимальному и максимальному индексу разделяемого массива, соответственно.
		\item Вычисляется индекс опорного элемента m.
		\item Индекс l последовательно увеличивается до тех пор, пока l-й элемент не окажется больше либо равен опорному.
		\item Индекс r последовательно уменьшается до тех пор, пока r-й элемент не окажется меньше либо равен опорному.
		\item Если r = l — найдена середина массива — операция разделения закончена, оба индекса указывают на опорный элемент.
		\item Если l < r — найденную пару элементов нужно обменять местами и продолжить операцию разделения с тех значений l и r, которые были достигнуты. Следует учесть, что если какая-либо граница (l или r) дошла до опорного элемента, то при обмене значение m изменяется на r-й или l-й элемент соответственно, изменяется именно индекс опорного элемента и алгоритм продолжает свое выполнение.
	\end{enumerate}
	\item Рекурсивно упорядочиваем подмассивы, лежащие слева и справа от опорного элемента.
\subsubsection{Оценка сложности}
Разделение массива: O(n). \\
\textbf{Лучший случай} \\
Массив делится на две почти одинаковые части, максимальная глубина рекурсии $\log_2 n$. Количество сравнений: $C_n = 2 \cdot C_{n/2} + n$, что даёт общую сложность $O(n \cdot \log_2 n)$. \\
\textbf{Среднее} \\
Среднюю сложность при случайном распределении входных данных можно оценить лишь вероятностно.
Прежде всего необходимо заметить, что в действительности необязательно, чтобы опорный элемент всякий раз делил массив на две одинаковых части. Например, если на каждом этапе будет происходить разделение на массивы длиной 75 процентов и 25 процентов от исходного, глубина рекурсии будет равна $\log_{4/3} n$, а это по-прежнему даёт сложность $O(n \log n)$. Вообще, при любом фиксированном соотношении между левой и правой частями разделения сложность алгоритма будет той же, только с разными константами. \\
Будем считать «удачным» разделением такое, при котором опорный элемент окажется среди центральных 50 процентов элементов разделяемой части массива; ясно, вероятность удачи при случайном распределении элементов составляет 0,5. При удачном разделении размеры выделенных подмассивов составят не менее 25 процентов и не более 75 процентов от исходного. Поскольку каждый выделенный подмассив также будет иметь случайное распределение, все эти рассуждения применимы к любому этапу сортировки и любому исходному фрагменту массива. \\
Удачное разделение даёт глубину рекурсии не более $\log_{4/3} n$. Поскольку вероятность удачи равна 0,5, для получения k удачных разделений в среднем потребуется $2 \cdot k$ рекурсивных вызовов, чтобы опорный элемент k раз оказался среди центральных 50 процентов массива. Применяя эти соображения, можно заключить, что в среднем глубина рекурсии не превысит $2 \cdot \log_{4/3} n$, что равно $O(\log n)$ А поскольку на каждом уровне рекурсии по-прежнему выполняется не более O(n) операций, средняя сложность составит $O(n \log n)$. \\
\textbf{Худший случай} \\
В самом несбалансированном варианте каждое разделение даёт два подмассива размерами 1 и n-1, то есть при каждом рекурсивном вызове больший массив будет на 1 короче, чем в предыдущий раз. Такое может произойти, если в качестве опорного на каждом этапе будет выбран элемент либо наименьший, либо наибольший из всех обрабатываемых. При простейшем выборе опорного элемента — первого или последнего в массиве, — такой эффект даст уже отсортированный (в прямом или обратном порядке) массив, для среднего или любого другого фиксированного элемента «массив худшего случая» также может быть специально подобран. В этом случае потребуется n-1 операций разделения, а общее время работы составит $\sum_{i=0}^n (n-i) = O(n^2)$ операций, то есть сортировка будет выполняться за квадратичное время. Но количество обменов и, соответственно, время работы — это не самый большой его недостаток. Хуже то, что в таком случае глубина рекурсии при выполнении алгоритма достигнет n, что будет означать n-кратное сохранение адреса возврата и локальных переменных процедуры разделения массивов. Для больших значений n худший случай может привести к исчерпанию памяти (переполнению стека) во время работы программы.

\end{itemize}


\subsection{Merge Sort}
\subsection{Heap Sort}

\section{Hash-table and hash-function}

\section{Динамическое программирование: общая идея. Линейная и матричная динамика. Динамика на отрезках}

\section{Амортизационный анализ}

\section{RMQ and LCA}
\subsection{RQM}
\subsection{LCA: сведение к RQM}
\subsection{Метод двоичного подъема}

\section{Алгоритмы на деревьях}
\subsection{Декартовы деревья}
Декартово дерево — это двоичное дерево, в узлах которого хранятся:
\begin{itemize}
	\item ссылки на правое и левое поддерево;
	\item ссылка на родительский узел (необязательно);
	\item ключи $x$ и $y$, которые являются двоичным деревом поиска по ключу $x$ и двоичной кучей по ключу $y$; а именно, для любого узла дерева $n$:
	\begin{itemize}
		\item ключи $x$ узлов правого (левого) поддерева больше (меньше либо равны) ключа $x$ узла $n$;
		\item ключи $y$ узлов правого и левого детей больше либо равны ключу $y$ узла $n$.
	\end{itemize}
\end{itemize}
Ссылка на родительский узел не обязательна, она желательна только для линейного алгоритма построения дерева.По сути, декартово дерево - это структура данных, объединяющая в себе бинарное кучу и двоичное дерево поиска. Декартово дерево не является самобалансирующемся деревом в обычном смысле (в
отличие от красно-черных деревьев). \\
Преимущества:\begin{enumerate}
	\item Легко и быстро реализуется, в отличие от красно-черных деревьев.
	\item Для случайного набора ключей y (относительно кучи) хорошо строится.
	\item Операция ―разделить по ключу х‖ выполняется за линейное время.
\end{enumerate}
Недостатки: \begin{enumerate}
	\item Большие расходы памяти: в каждой вершине нужно хранить два-три указателя и два ключа.
	\item Скорость доступа в худшем случае - O(n), поэтому декартово дерево не применяется в ядрах ОС.
\end{enumerate}
\subsubsection{Операции на декартовых деревьях}
\begin{enumerate}
	\item Split
	Операция Split позволяет разрезать декартово дерево $T$ по ключу $k$ и получить два других декартовых дерева: $T_1$ и $T_2$, причем в $T_1$ находятся
все ключи дерева $T$, не большие $k$, а в $T_2$ — большие $k$. \\
Рассмотрим случай, в котором требуется разрезать дерево по ключу, большему ключа корня. Посмотрим, как будут устроены результирующие деревья $T_1$ и $T_2$:
\begin{itemize}
	\item $T_1$ : левое поддерево $T_1$ совпадѐт с левым поддеревом $T$. Для нахождения правого поддерева $T_1$, нужно разрезать правое поддерево $T$ на $T_1^R$ и $T_2^R$ по ключу $k$ и взять $T_1^R$
	\item $T_2$ совпадѐт с $T_2^R$.
\end{itemize}
Случай, в котором требуется разрезать дерево по ключу, меньше либо равному ключа в корне, рассматривается симметрично. \\
Псевдокод: \\
Split(Treap t, int k, Treap \&t1, Treap \&t2) \\
if t == NULL\\
	\tab{t1 = t2 = NULL;}\\
else \\
 	\tab{if k > t.x}\\
 		\tab{\tab{Split(t.right, k, t.right, t2);}}\\
 		\tab{\tab{t1 = t;}}\\
 	\tab{else}\\
 		\tab{\tab{Split(t.left, k, t1, t.left);}}\\
 t2 = t;\\
 \todo{fix spacing}
Оценим время работы операции. Во время выполнения вызывается одна операция для дерева хотя бы на один меньшей высоты и делается ещѐ $O(1)$ операция. Тогда итоговая трудоѐмкость этой операции равна $O(h)$, где $h$ — высота дерева

\item Merge

\end{enumerate}
\subsubsection{Декартово дерево по неявному ключу}

\subsection{Минимальное основное дерево}
\subsubsection{Алгоритм Прима}
Алгоритм построения минимального остовного дерева (дерево, сумма весов ребер которого минимальна) \\
Вход: взвешенный граф (неориентированный) \\
Алгоритм:
\begin{enumerate}
	\item Выбираем некоторую стартовую вершину
	\item Из этой вершины строим самый дешевый путь
	\item Берем связанные вершины и строим самые дешевые пути из них (не рассматриваем те, которые образуют цикл)
	\item Продолжаем до тех пор, пока не свяжем все вершины
\end{enumerate}
Примечания: \\
$\bullet$ Для быстрого нахождения минимальных путей рекомендуется использовать биномиальную кучу. \\
$\bullet$ Интерпретация задачи: есть некое множество городов (и расстояний между ними) - нужно построить самую дешевую сеть дорого (самую короткую) \\
Сложность зависит от способа представления графа и приоритетной очереди:
\begin{itemize}
	\item Массив d, списки смежности (матрица смежности): $O(|V|^2)$
	\item Бинарная пирамида, списки смежности: $O(E \log V)$
	\item Фибоначчиева пирамида, списки смежности: $O(E + V \log V)$
\end{itemize}
\subsubsection{Алгоритм Крускала}
Качественный алгоритм для топологической сортировки \\
Условия: имеем ацикличный ориентированный граф. Упорядочиваем согласно частичному порядку. \\
Алгоритм:
\begin{enumerate}
	\item Берем случайную вершину
	\item Выполняем из нее DFS со следующей особенностью: черные вершины автоматически заносятся в стек, и помечаются использованными
	\item Повторяем п.2 для неиспользованных вершин
	\item Извлекаем ответ из стека
\end{enumerate} \\
Сложность: $O(|E| + |V|)$

\section{Минимальные потоки в сети}
\subsection{Метод Форда-Фалкерсона}
Решает задачу нахождения максимального потока транспортной сети. \\
Алгоритм:
\begin{enumerate}
	\item Обнуляем все потоки. Остаточная сеть изначально совпадает с исходной сетью.
	\item В остаточной сети находим любой путь из источника в сток. Если такого пути нет, останавливаемся.
	\item 3 Пускаем через найденный путь (он называется увеличивающим путѐм или увеличивающей цепью) максимально возможный поток:
	\begin{itemize}
	 	\item На найденном пути в остаточной сети ищем ребро с минимальной пропускной способностью $c_{min}$.
		\item Для каждого ребра на найденном пути увеличиваем поток на $c_{min}$, а в противоположном ему — уменьшаем на $c_{min}$.
		\item Модифицируем остаточную сеть. Для всех рѐбер на найденном пути, а также для противоположных им рѐбер, вычисляем новую пропускную способность. Если она стала ненулевой, добавляем ребро к остаточной сети, а если обнулилась, стираем его.
	\end{itemize}
	\item Возвращаемся на шаг 2.
\end{enumerate}
Алгоритм (формально):\\
Вход: Граф с пропускной способностью, источник и сток\\
Выход: Максимальный поток $f$ из $s$ в $t$\\
\begin{enumerate}
	\item $f(u,v) \leftarrow 0 \forall (u,v)$
	\item Пока есть путь $p$ из $s$ в $t$ в $G_f$, такой что $c_f(u,v)>0 \forall (u,v) \in p$:
	\begin{enumerate}
		\item Найти $c_f(p) = \min\{c_f(u,v)|(u,v) \in p\}$
		\item $\forall (u,v) \in p$:
		\begin{itemize}
			\item $f(u,v) \leftarrow f(u,v) + c_f(p)$
			\item $f(v,u) \leftarrow f(v,u) - c_f(p)$
		\end{itemize}
	\end{enumerate}
\end{enumerate}
Сложность: $O(E*f)$
\subsection{Метод Эдмондса-Карпа (б/д)}

\section{Алгоритмы на графах}
\subsection{Обход в ширину и глубину}
\subsubsection{Обход в глубину}
Сложность: $O(|E| + |V|)$
\begin{enumerate}
	\item Присваиваем всем вершинам белый цвет
	\item Берем произвольную белую вершину
	\item Красим в серый
	\begin{itemize}
		\item Если есть белый потомок, переходим в него и goto 3
		\item Если нет, красим в черный, переходим к родителю и goto 3a
		\item Если нет родителя и есть белые вершины goto 2
		\item Не осталось белых – конец алгоритма
	\end{itemize}
\end{enumerate}

\subsubsection{Обход в ширину}
Сложность: $O(|E| + |V|)$
\begin{enumerate}
	\item Берем произвольную вергину
	\item Добавляем в очередь (пометив как пройденную)
	\item Пока очередь не пуста
	\begin{itemize}
		\item Достаем первую вершин
		\item Добавляем в очередь все непройденные потомки
		\item goto 3
	\end{itemize}
\end{enumerate}

\subsection{Поиск кратчайших путей в графе}
\subsubsection{Алгоритм Дейкстры}
Вход: взвешенный граф (веса положительны), стартовая вершина\\
Выход: ветор расстояний до стартовой вершины (опционально - вектор предков, чтобы восстановить кратчайший путь)\\
Алгоритм:
\begin{enumerate}
	\item Проставляем расстояния: для стартовой 0, для остальных inf
	\item Пусть S - множество вершин, до которых ихзвестны кратчайшие пути
	\item Добавляем в S вершину с минимальным расстоянием из вектора расстояний и еще не находящуюся в множестве. Помечаем ее, как добавленную.
	\item Для всех соседей обновляем оценку:
	\begin{itemize}
		\item  Сосед ib 
		\item Вершина v
		\item Новая оценка для i = min(старая, d(start, v)+d(v,i))
	\end{itemize}
	\item Если еще остались неиспользованные goto 2
\end{enumerate}
Сложность: $O(|E| + |V|^2)$

\subsubsection{Алгоритм Форда-Беллмана}
Алгоритм поиска кратчайшего пути во взвешенном графе\\
Условие: взвешенный граф, можно с отрицательными весами и циклами (с добавлением дополнительной проверки), стартовая вершина.\\
Алгоритм (без отрицательных циклов):
\begin{enumerate}
	\item Для всех вершин проставляем расстояние = $\inf$
	\item Для начальной вершины расстояние = 0
	\item for i = 1 to (V - 1)
			$\forall (u ,v)$
				if $d[v] >  d[u] + w(u,v)$
					$d[v] = d[u] + w(u,v)$
	\item Возвращаем вектор расстояний
\end{enumerate}
Алгоритм (c отрицательными циклами):\\
Алгоритм Беллмана–Форда позволяет очень просто определить, существует ли в графе G отрицательный цикл, достижимый из вершины s. Достаточно произвести внешнюю итерацию цикла не $|V|-1$ , a ровно $|V|$ раз. Если при исполнении последней итерации длина кратчайшего пути до какой-либо вершины строго уменьшилась, то в графе есть отрицательный цикл, достижимый из s. На основе этого можно предложить следующую оптимизацию: отслеживать изменения в графе и, как только они закончатся, сделать выход из цикла (дальнейшие итерации будут бессмысленны).\\
Сложность: $O(|E|^*|V|)$

\subsubsection{Алгоритм Флойда-Уоршелла}
Вход: взвешенный орграф\\
Выход: матрица длин кратчайших путей.\\
Алгоритм:\\
for v = 1 to V\\
	\tab{for i = 1 to V}\\
			\tab{\tab{for j = 1 to V}}\\
				\tab{\tab{\tab{Table[i][j] = min (Table[i][j], Table[i][v] + Table[v][j]);}}} \\
Сложность: $O(|V|^3)$

\subsection{Поиск сильносвязных компонент в графе}
ССК - максимальный по включению сильно связанный подграф. Сильно связный граф - орграф, т. ч. из любой вершины можно попасть в любую.\\
Алгоритм находит ССК по данному графу.\\
Условия: дается орграф.\\
Алгоритм (Косарайю):
\begin{enumerate}
	\item Инвертируем граф (меняем направление всех ребер)
	\item Запускаем DFS на транспонированном (инвертированном) графе DFS.
	\item Для каждой вершины запоминаем время выхода (шаги), т. е. когда выходим из вершины окончательно (она становится черной)
	\item Запускаем DFS на исходном графе, в очередной раз выбирая вершину с максимальным номером (временем выхода)
	\item Полученные деревья в п.4 и есть искомые ССК (появляются, когда мы переходим к новой белой вершине в DFS)
\end{enumerate}
Сложность: $O(|E| + |V|)$ для разреженного и $O(|V|^2)$ для плотного графа. 
\subsection{Мосты и точки сочленения в графе}

\section{STL и стандартные контейнеры}
\subsection{vector, deque, queue, priority\_queue, set, map}
\subsection{Итераторы и компараторы}

\end{document}